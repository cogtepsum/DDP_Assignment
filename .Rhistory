p4 <- choose(9, 3)/choose(36, 3)
p1 + p2 + p3 + p4
x <- c(1, 2, 3, 4)
y <- c(23, 34, 12, 3)
x * y
choose(12, 3)*(0.5^3)*(0.5^9)
choose(5, 4)*(0.5^4)*(0.5^1)
choose(5, 4)*(0.5^4)*(0.5^1) + choose(5, 5)*(0.5^5)*(0.5^0)
150e-6
4^3*150e-6
4^3*150e-6/14^3
(4/14)^3\
(4/14)^3
150e-6 * (4/14)^3
2^6
(2^2)^3
1*exp(-4^3*10e-10*150e-6)
exp(-4^3*10e-10*150e-6)
exp(-4^3*10e-30*150e-6)
2^2*2^3
2^5
lmb <- 0.41e-9
dbe <- 150e-6
(4^3*lmb^3*dbe + 1)/(14^3*lmb^3)
(4^3*lmb^3*dbe)/(14^3*lmb^3)
(4^3*lmb^3*dbe + ln(1.5))/(14^3*lmb^3)
(4^3*lmb^3*dbe + log(1.5))/(14^3*lmb^3)
(4^3*lmb^3*dbe)/(14^3*lmb^3 + 1)
4^3*lmb^3/1.85e3
4^3*lmb^3*1.85e3
4^3*lmb^3
j <- ((e_const*(e_const*x)^2)/(4*pi^2*hbar_const*U0))*(sqrt(Ef/(U0-Ef)))*(exp(-(4*sqrt(2*me_const)/(e_const*x*hbar_const*3))*(U0-Ef)^(3/2)))
e_const <- 1.6022e-19
hbar_const <- 1.0546e-34
hbar_const + e_const
Ef <- 1.3619e-19
wFun <- 6.6490e-19
U0 <- wFun + Ef
x <- 5e7
j <- ((e_const*(e_const*x)^2)/(4*pi^2*hbar_const*U0))*(sqrt(Ef/(U0-Ef)))*(exp(-(4*sqrt(2*me_const)/(e_const*x*hbar_const*3))*(U0-Ef)^(3/2)))
me_const <- 9.1094e-31
j <- ((e_const*(e_const*x)^2)/(4*pi^2*hbar_const*U0))*(sqrt(Ef/(U0-Ef)))*(exp(-(4*sqrt(2*me_const)/(e_const*x*hbar_const*3))*(U0-Ef)^(3/2)))
j1 <- e_const*(e_const*x)^2 / (4*pi*hbar_const)
j1 <- e_const*(e_const*x)^2 / (4*pi*hbar_const) * 1/U0
j1 <- e_const*(e_const*x)^2 / (4*pi*hbar_const) * 1/U0 * sqrt(Ef/(U0 - Ef))
j2 <- exp(-(4*sqrt(2*me_const)/(3*e_const*x*hbar_const))*(U0-Ef)^1.5)
U0-Ef
-(4*sqrt(2*me_const)/(3*e_const*x*hbar_const))*(U0-Ef)^1.5
e(-1154.938)
exp(-1154.938)
exp(-1154)
exp(-115)
exp(-1150)
exp(-999)
exp(-500)
j2 <- exp((4*sqrt(2*me_const)/(3*e_const*x*hbar_const))*(U0-Ef)^1.5)
j2 <- exp(-(4*sqrt(2*me_const)/(3*e_const*x*hbar_const))*(U0-Ef)^1.5)
j2 <- exp(-(4*sqrt(2*me_const)/(3)*(e_const*x*hbar_const))*(U0-Ef)^1.5)
j1*j2
j1*j2/10000
h <- 6.6261e-34
e <- e_const
m <- me_const
phi <- wFun
(e^3/(8*pi*h))*(x^2/(phi))*exp(-(8*pi*sqrt(2*m)/(3*h*e))*(phi^1.5/x)*0.8)
e*sqrt(e*x)/phi
(e^3/(8*pi*h))*(x^2/(phi))*exp(-(8*pi*sqrt(2*m)/(3*h*e))*(phi^1.5/x))
-(8*pi*sqrt(2*m)/(3*h*e))*(phi^1.5/x)
j2 <- exp(-(4*sqrt(2*m)/(3*e*x*hbar_const))*phi^(3/2))
x <- 9e9
j2 <- exp(-(4*sqrt(2*m)/(3*e*x*hbar_const))*phi^(3/2))
j1 <- e*(e*x)^2 / (4*pi*hbar_const) * 1/U0 * sqrt(Ef/(U0 - Ef))
j1 <- (e*(e*x)^2)/(4*pi^2*hbar_const) * 1/(Ef + phi) * sqrt(Ef/phi)
x <- 5e7
j1 <- (e*(e*x)^2)/(4*pi^2*hbar_const) * 1/(Ef + phi) * sqrt(Ef/phi)
j2 <- exp(-(4*sqrt(2*m)/(3*e*x*hbar_const))*phi^(3/2))
x <- 5e9
j1*j2
x <- 9e9
j1 <- (e*(e*x)^2)/(4*pi^2*hbar_const) * 1/(Ef + phi) * sqrt(Ef/phi)
j2 <- exp(-(4*sqrt(2*m)/(3*e*x*hbar_const))*phi^(3/2))
j1*j2
?log
2^log2(5)
5^log2(5)
logb(5*2, base = 3)
logb(5, base = 3) + logb(2, base=3)
5^logb(7, base=3)
7^logb(5, base=3)
data("mtcars")
fit <- lm(mpg ~ cyl, mtcars)
summary(fit)
fit <- lm(mpg ~ factor(cyl), mtcars)
summary(fit)
fit <- lm(mpg ~ factor(cyl)+wt, mtcars)
summary(fit)
fit2 <- lm(mpg ~ cov(cyl, wt), mtcars)
fit2 <- lm(cel ~ wt, mtcars)
fit2 <- lm(cyl ~ wt, mtcars)
summary(fit2)
fit1 <- lm(mpg ~ factor(cyl), mtcars)
fit2 <- lm(mpg ~ factor(cyl) + wt, mtcars)
anova(fit1, fit2)
?mtcars
summary(lm(mpg ~ I(wt*0.5) + factor(cyl), mtcars))
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
hatvalues(lm(y ~ x))
hat(x)
hat(y)
hatvalues(lm(y ~ x)[1:5])
hatvalues(lm(y ~ x))[1:5]
dfbeta(lm(y ~ x))
dfbetas(lm(y ~ x))
summary(lm(mpg ~ wt + factor(cyl), mtcars))
summary(lm(mpg ~ I(wt*0.5) + factor(cyl), mtcars))
summary(lm(mpg ~ wt + factor(cyl), mtcars))
summary(lm(mpg ~ factor(cyl), mtcars))
anova(fit1, fit2)
t.test(fit1, fit2)
anova(fit2, fit1)
vif(fit1)
library(car)
install.packages('vif')
install.packages('car')
fit1 <- lm(mpg ~ factor(cyl) + wt, mtcars)
fit2 <- lm(mpg ~ factor(cyl) + wt + I(factor(cyl)*wt), mtcars)
fit2 <- lm(mpg ~ factor(cyl) + wt + I(cyl*wt), mtcars)
anova(fit1, fit2)
plot(mpg, factor(wt), mtcars)
plot(mtcars$mpg, factor(mtcars$wt))
plot(factor(mtcars$wt), mtcars$mpg)
abline(fit1)
abline(fit2)
fit <- lm(mpg ~ factor(cyl), mtcars)
anova(fit, fit1, fit2)
library(ggplot2)
g <- ggplot(data = mtcars, aes(factor(cyl), mpg, wt))
g
qplot(data = mtcars, aes(factor(cyl), mpg, wt))
qplot(data = mtcars, aes(factor(cyl), mpg))
qplot(data = mtcars, factor(cyl), mpg)
qplot(data = mtcars, factor(cyl), mpg, wt)
qplot(data = mtcars, factor(cyl), mpg, color=wt)
qplot(wt, mpg, data=mtcars, geom=c("point", "smooth"),
method="lm", formula=y~x, color=cyl,
main="Regression of MPG on Weight",
xlab="Weight", ylab="Miles per Gallon")
qplot(wt, mpg, data=mtcars, geom=c("point", "smooth"),
method="lm", formula=y~x, color=cyl,
main="Regression of MPG on Weight",
xlab="Weight", ylab="Miles per Gallon") + geom_smooth(mpg ~ factor(cyl) + wt + I(cyl * wt))
qplot(wt, mpg, data=mtcars, geom=c("point", "smooth"),
method="lm", formula=y~x+wt, color=cyl,
main="Regression of MPG on Weight",
xlab="Weight", ylab="Miles per Gallon") + geom_smooth(aes())
qplot(wt, mpg, data=mtcars, geom=c("point", "smooth"),
method="lm", formula=y~x+mtcars$wt, color=cyl,
main="Regression of MPG on Weight",
xlab="Weight", ylab="Miles per Gallon") + geom_smooth(aes())
qplot(factor(cyl), mpg, data=mtcars, geom=c("point", "smooth"),
method="lm", formula=y~x, color=cyl,
main="Regression of MPG on Weight",
xlab="Weight", ylab="Miles per Gallon") + geom_smooth(aes())
qplot(factor(cyl), mpg, data=mtcars, geom=c("point", "smooth"),
method="lm", formula=y~x, color=cyl,
main="Regression of MPG on Weight",
xlab="Weight", ylab="Miles per Gallon")
qplot(cyl, mpg, data=mtcars, geom=c("point", "smooth"),
method="lm", formula=y~x, color=cyl,
main="Regression of MPG on Weight",
xlab="Weight", ylab="Miles per Gallon")
qplot(cyl+wt, mpg, data=mtcars, geom=c("point", "smooth"),
method="lm", formula=y~x, color=cyl,
main="Regression of MPG on Weight",
xlab="Weight", ylab="Miles per Gallon")
qplot(cyl+wt, mpg, data=mtcars, geom=c("point", "smooth"),
method="lm", formula=y~x, color=cyl,
main="Regression of MPG on Weight",
xlab="Weight", ylab="Miles per Gallon") + geom_smooth(aes(cyl + wt + wt*cyl, mpg), data = mtcars)
qplot(cyl+wt, mpg, data=mtcars, geom=c("point", "smooth"),
method="lm", formula=y~x, color=cyl,
main="Regression of MPG on Weight",
xlab="Weight", ylab="Miles per Gallon") + geom_smooth(aes(cyl + wt + wt*cyl, mpg), data = mtcars, method='lm')
qplot(cyl+wt+ wt*cyl, mpg, data=mtcars, geom=c("point", "smooth"),
method="lm", formula=y~x, color=cyl,
main="Regression of MPG on Weight",
xlab="Weight", ylab="Miles per Gallon") + geom_smooth(aes(cyl + wt), data = mtcars, method='lm')
qplot(wt*cyl, mpg, data=mtcars, geom=c("point", "smooth"),
method="lm", formula=y~x, color=cyl,
main="Regression of MPG on Weight",
xlab="Weight", ylab="Miles per Gallon") + geom_smooth(aes(cyl + wt), data = mtcars, method='lm')
qplot(wt, mpg, data=mtcars, geom=c("point", "smooth"),
method="lm", formula=y~x, color=cyl,
main="Regression of MPG on Weight",
xlab="Weight", ylab="Miles per Gallon")
qplot(cyl, mpg, data=mtcars, geom=c("point", "smooth"),
method="lm", formula=y~x, color=cyl,
main="Regression of MPG on Weight",
xlab="Weight", ylab="Miles per Gallon")
summary(fit3)
summary(fit2)
fit2 <- lm(mpg ~ cyl*wt, mtcars)
anova(fit1, fit2)
fit2 <- lm(mpg ~ I(cyl*wt), mtcars)
anova(fit1, fit2)
anova(fit, fit1, fit2)
qplot(cyl, wt, data=mtcars, geom=c("point", "smooth"),
method="lm", formula=y~x, color=cyl)
fit3 <- lm(mpg ~ factor(cyl) + wt + wt*cyl, mtcars)
anova(fit, fit1, fit2, fit3)
anova(fit1, fit3)
fit3 <- lm(mpg ~ factor(cyl) + wt + I(wt*cyl), mtcars)
anova(fit1, fit3)
anova(fit1$coefficients[2], fit3$coefficients[2])
t.test(fit1$coefficients[2], fit3$coefficients[2])
t.test(fit1, fit3)
summary(fit3)
qplot(factor(cyl) + wt + I(cyl*wt), mpg, data=mtcars, geom=c("point", "smooth"),
method="lm", formula=y~x, color=cyl)
qplot(mpg, factor(cyl) + wt + I(cyl*wt), data=mtcars, geom=c("point", "smooth"),
method="lm", formula=y~x, color=cyl)
qplot(factor(cyl), mpg, data=mtcars, geom=c("point", "smooth"),
method="lm", formula=y~x, color=cyl)
qplot(factor(cyl) + wt, mpg, data=mtcars, geom=c("point", "smooth"),
method="lm", formula=y~x, color=cyl)
qplot(cyl + wt + I(cyl*wt), mpg, data=mtcars, geom=c("point", "smooth"),
method="lm", formula=y~x, color=cyl)
qplot(cyl + wt, mpg, data=mtcars, geom=c("point", "smooth"),
method="lm", formula=y~x, color=cyl)
qplot(cyl * wt, mpg, data=mtcars, geom=c("point", "smooth"),
method="lm", formula=y~x, color=cyl)
qplot(wt + cyl * wt, mpg, data=mtcars, geom=c("point", "smooth"),
method="lm", formula=y~x, color=cyl)
qplot(cyl + wt + cyl * wt, mpg, data=mtcars, geom=c("point", "smooth"),
method="lm", formula=y~x, color=cyl)
fit3$residuals
anova(fit, fit1, fit3)
fit2 <- lm(mpg ~ factor(cyl) * wt)
fit2 <- lm(mpg ~ factor(cyl) * wt, mtcars)
anova(fit1, fit2)
summary(fit2)
data("mtcars")
summary(lm(mpg ~ factor(am)*wt, mtcars))
summary(lm(mpg ~ factor(am)*wt + qsec, mtcars))
plot(mpg ~ am, mtcars)
abline(lm(mpg ~ factor(am)*wt + qsec, mtcars))
abline(lm(mpg ~ factor(am)*wt, mtcars))
install.packages('caret')
library(caret)
install.packages("caret")
install.packages("MASS")
install.packages("car")
install.packages("ld")
installed.packages('car')
installed.packages('caret')
install.packages('car')
install.packages('car')
install.packages('caret')
install.packages('kernlab')
install.packages('parallel')
install.packages('doParallel')
install.packages('foreach')
install.packages('AppliedPredictiveModeling')
install.packages('caret')
install.packages('ElemStatLearn')
install.packages('pgmm')
install.packages('rpart')
install.packages('gbm')
install.packages('lubridate')
install.packages('forecast')
install.packages('e1071')
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
rf <- train(y ~ ., data = vowel.train, method = 'rf')
library(caret)
rf <- train(y ~ ., data = vowel.train, method = 'rf')
set.seed(33833)
rf <- train(y ~ ., data = vowel.train, method = 'rf')
gbm <- train(y ~ ., data = vowel.train, method = 'gbm')
pred1 <- predict(rf, vowel.test)
pred2 <- predict(gbm, vowel.test)
confusionMatrix(pred1, vowel.test$y)
confusionMatrix(pred2, vowel.test$y)
predDF <- data.frame(pred1, pred2, vowel.test$y)
combMod <- train(y ~ ., method = 'gam', data = predDF)
predDF <- data.frame(pred1, pred2, y=vowel.test$y)
combMod <- train(y ~ ., method = 'gam', data = predDF)
combPred <- predict(combMod, predDF)
confusionMatrix(combPred, predDF)
confusionMatrix(combPred, predDF$y)
confusionMatrix(combPred, vowel.test$y)
predDF <- data.frame(p1 = pred1, p2 = pred2, y=vowel.test$y)
combMod <- train(y ~ ., method = 'gam', data = predDF)
combPred <- predict(combMod, predDF)
confusionMatrix(combPred, predDF$y)
combMod <- train(y ~ ., data = predDF)
combPred <- predict(combMod, predDF)
confusionMatrix(combPred, predDF$y)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
m1 <- train(diagnosis ~ ., data = training, method = 'rf')
summary(m1)
str(m1)
m2 <- train(diagnosis ~ ., data = training, method = 'gbm')
m3 <- train(diagnosis ~ ., data = training, method = 'lda')
pred1 <- predict(m1, testing)
pred2 <- predict(m2, testing)
pred3 <- predict(m3, testing)
confusionMatrix(pred1, testing$diagnosis)$Accuracy
confusionMatrix(pred1, testing$diagnosis)$acc
confusionMatrix(pred1, testing$diagnosis)$accuracy
confusionMatrix(pred1, testing$diagnosis)
confusionMatrix(pred2, testing$diagnosis)
confusionMatrix(pred3, testing$diagnosis)
predDF <- data.frame(pred1, pred2, pred3, testing$diagnosis)
combModFit <- train(diagnosis ~ ., data = predDF, method = 'rf')
predDF <- data.frame(pred1, pred2, pred3, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., data = predDF, method = 'rf')
combPred <- predict(combModFit, predDF)
confusionMatrix(combPred, predDF$diagnosis)
set.seed(62433)
m1 <- train(diagnosis ~ ., data = training, method = 'rf')
m2 <- train(diagnosis ~ ., data = training, method = 'gbm')
m3 <- train(diagnosis ~ ., data = training, method = 'lda')
pred1 <- predict(m1, testing)
pred2 <- predict(m2, testing)
pred3 <- predict(m3, testing)
confusionMatrix(pred1, testing$diagnosis)
confusionMatrix(pred2, testing$diagnosis)
confusionMatrix(pred3, testing$diagnosis)
predDF <- data.frame(pred1, pred2, pred3, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., data = predDF, method = 'rf')
combPred <- predict(combModFit, predDF)
confusionMatrix(combPred, predDF$diagnosis)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
?plot.enet
??plot.enet
mFit <- train(CompressiveStrength ~ ., data = concrete, method = 'lasso')
?plot.enet
plot.enet(nFit)
plot.enet(mFit)
plot.enet(x = mFit)
plot(x = mFit)
plot(x = mFit, xvar = 'penalty')
plot(x = mFit, xvar = 'step')
plot(x = mFit, xvar = 'L1norm')
plot.enet(x = mFit, xvar = 'L1norm')
mFit
coefficients(mFit)
mFit <- train(CompressiveStrength ~ ., data = concrete, method = 'lasso')
mFit <- train(CompressiveStrength ~ ., data = concrete, method = 'enet')
plot(x = mFit, xvar = 'step')
mFit <- train(CompressiveStrength ~ ., data = concrete, method = 'lasso')
mFit$beta.pure
plot(x = mFit, xvar = 'step')
plot.enet(mFit, xvar = 'step')
mFit <- train(CompressiveStrength ~ ., data = concrete, method = 'lasso', na.action = na.roughfix)
plot.enet(mFit, xvar = 'step')
plot.enet(mFit)
mFit <- train(CompressiveStrength ~ ., data = concrete, method = 'lasso')
mFit <- train(CompressiveStrength ~ ., data = training, method = 'lasso')
plot.enet(mFit)
mFit
mFit$finalModel
plot.enet(mFit$finalModel)
plot.enet(mFit$finalModel['CoarseAggregate'])
plot.enet(mFit$finalModel)
plot.enet(mFit$finalModel, cex = 0.5)
plot.enet(mFit$finalModel, cex.lab = 0.5)
plot.enet(mFit$finalModel, cex.axis = 0.5)
help(par)
plot.enet(mFit$finalModel, cex.sub = 0.5)
plot.enet(mFit$finalModel, cex.main = 0.5)
plot.enet(mFit$finalModel, cex = 0.5)
plot.enet(mFit$finalModel, cex.axis = 0.5)
plot.enet(mFit$finalModel, ps = 0.5)
plot.enet(mFit$finalModel, font.axis = 0.5)
plot.enet(mFit$finalModel, cex = 0.5)
plot.enet(mFit$finalModel, cex = 0.1)
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
mFit <- bats(training)
mFit <- bats(visitsTumblr ~ ., data = training)
mFit <- bats(training, use.parallel = F)
mFit <- bats(training)
mFit <- bats(tstrain)
pred <- forecast.bats(mFit, testing$date)
pred <- forecast.bats(mFit, testing)
pred <- forecast.bats(mFit, 235)
confusionMatrix(pred, testing$visitsTumblr)
confusionMatrix(pred$y, testing$visitsTumblr)
confusionMatrix(pred$, testing$visitsTumblr)
confusionMatrix(pred$x, testing$visitsTumblr)
accuracy(pred)
accuracy(pred, testing$visitsTumblr)
summary(pred)
pred$forecasts
pred$Forecasts
sum(sapply(testing$visitsTumblr >= pred$lower & testing$visitsTumblr <= pred$upper))
s <- 0
for i in 1:325;
for i in 1:325 {
if (testing[i, 'visitsTumblr'] >= pred$lower[i] & testing[i, 'visitsTumblr'] <= pred$upper[i]) {
s <- s + 1
}
}
for i in 1:325 {
if (testing['visitsTumblr', i] >= pred$lower[i] & testing[i, 'visitsTumblr'] <= pred$upper[i]) {
s <- s + 1
}
}
for (i in 1:325) {
if (testing[i, 'visitsTumblr'] >= pred$lower[i] & testing[i, 'visitsTumblr'] <= pred$upper[i]) {
s <- s + 1
}
}
for (i in 1:235) {
if (testing[i, 'visitsTumblr'] >= pred$lower[i] & testing[i, 'visitsTumblr'] <= pred$upper[i]) {
s <- s + 1
}
}
s
s <- 0
for (i in 1:235) {
if (testing[i, 'visitsTumblr'] >= pred$lower[i] & testing[i, 'visitsTumblr'] <= pred$upper[i]) {
s <- s + 1
}
}
s
201/235
pred <- forecast.bats(mFit, 235, level = 95)
pred <- forecast(mFit, 235, level = 95)
accuracy(pred, testing$visitsTumblr)
s <- 0
for (i in 1:235) {
if (testing$visitsTumblr[i] > pred$lower[i] & testing$visitsTumblr[i] < pred$upper[i]) {
s <- s + 1
}
}
s
s/235 * 100
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
mFit <- train(CompressiveStrength ~ ., data = training, method = 'svm')
library(e1071)
mFit <- svm(CompressiveStrength ~ ., data = training)
pred <- predict(mFit, testing)
summary(pred)
summary(mFit)
rmse <- function(error)
{
sqrt(mean(error^2))
}
error <- mFit$residuals
predictionRMSE <- rmse(error)
install.packages('shinyapps')
install.packages('shiny')
library(devtools)
install_github('rstudio/shinyapps')
install_github('slidify', 'ramnathv')
install_github('slidifyLibraries', 'ramnathv')
install_github('ramnathv/slidify')
install_github('ramnathv/slidifyLibraries')
install_github('ramnathv/rCharts')
install.packages('googleVis')
install.packages('leaflet')
install_github("ropensci/plotly")
Slide With Code
- Bullet 2
source('~/Desktop/xray_attenuation_plot.R')
shiny::runApp('Desktop/kmeansexample')
library(shinyapps)
setwd("~/Desktop/kmeansexample")
deployApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
deployApp()
